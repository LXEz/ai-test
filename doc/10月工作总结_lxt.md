# Auto-gpt 研究

## 工作内容

1. 搭建 auto-gpt 的本地服务
2. 扩展 llm 支持，添加通义千问
3. 基于 auto-gpt 搭建基于 graph 的 Agent，探索 auto-gpt 的运行机制、能力边界、扩展性

## 研究总结

1. auto-gpt 从 ai 的外部，探索在不侵入 ai 的情况下，来构建基于 ai 的应用程序
2. auto-gpt 呈现给用户的更倾向于通过可视的图形化的界面来搭建 ai 应用，而不是通过编码，这一点有点类似基于 ai 的低代码

## 结论

目前针对我们需要实现的目标：

**针对特定的领域，特定的技术栈生成全栈的项目代码**

在现有的场景下，auto-gpt 的方案存在以下局限性:

1. 知识局限：auto-gpt 无法直接访问和理解现有的业务逻辑、代码库和技术栈。这些本地化的信息对于生成符合特定需求的代码至关重要。

2. 上下文理解不足：由于无法深入理解项目的整体结构和上下文，auto-gpt 生成的代码可能与现有系统不一致或难以集成。

3. 定制化能力有限：auto-gpt 将 AI 视为黑盒，用户难以根据项目需求灵活定制 AI 的行为，这限制了其在特定领域的应用效果。

为了更好地实现我们的目标，我们需要探索一种能够将本地知识与 AI 能力深度融合的方案。这种方案应该能够：

1. 自动理解和利用先有的代码库和业务逻辑
2. 提供更灵活的 AI 定制化能力
3. 深度整合本地资源和知识库

这可能需要我们开发一个更加开放和可定制的 AI 辅助编程系统，而不仅仅依赖于现有的 auto-gpt 框架。

## 附加链接

[基于 auto-gpt 的 agent 以什么样的形式存在](http://192.168.99.63:3000/wJTs3XJrS6iVKE4JY2C16Q)

# RAG 研究

## 工作内容

1. 基于 open-webui 搭建调用本地 ollama 大模型的 RAG 应用(http://192.168.99.11/)
2. 上传本地文档，简单测试 llm+RAG 的应用效果
3. 通过默认的 RAG 搭建策略构建的本地知识库，实际使用效果不佳，开始深入研究 RAG 搭建的每个环节，寻求在这些环节做本地优化调整，以搭建符合我们的需求的本地知识库
