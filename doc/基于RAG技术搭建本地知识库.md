# 什么是 RAG

大型语言模型（LLMs）所实现的最强大应用之一是复杂的问答（Q&A）聊天机器人。这些应用能够回答关于特定源信息的问题。这些应用使用一种被称为检索增强生成（Retrieval Augmented Generation，简称 RAG）的技术。

RAG 是一种用额外数据增强 LLM 知识的技术。

LLM 可以对广泛的主题进行推理，但它们的知识仅限于训练时截止日期之前的公开数据。如果你想构建能够对私有数据或模型截止日期之后引入的数据进行推理的 AI 应用，你需要用它所需的特定信息来增强模型的知识。将适当的信息引入并插入到模型提示中的过程被称为检索增强生成（RAG）。

## 实现 RAG 的一般步骤

一个典型的 RAG 应用通常包含两个主要部分：

- 索引：从数据源摄取数据并建立索引。这通常在离线状态下进行。
- 检索和生成：实际的 RAG 链，它在运行时接收用户查询，从索引中检索相关数据，然后将其传递给模型。

## 建立 Indexing

- Load：首先我们需要加载我们的数据。这通过文档加载器来完成。
- Split：文本分割器将大型文档分割成更小的块。这对于索引数据和将其传递给模型都很有用，因为大块数据更难搜索，而且无法适应模型有限的上下文窗口。
- Embed：嵌入模型将文本转换为向量表示。这些向量用于相似性搜索和检索。
- Store：我们需要一个地方来存储和索引我们的分割，以便之后可以对其进行搜索。这通常使用向量存储和嵌入模型来完成。

![](http://192.168.99.63:3000/uploads/upload_c5d765601537257c91519e4b931a5640.png)

## 检索和生成(Retrieval and generation)

- Retrieve: 给定一个用户输入，使用 Retriever 从存储中检索相关分割。
- Generate: 一个 ChatModel / LLM 使用一个包含问题和检索数据的提示来生成答案。

![](http://192.168.99.63:3000/uploads/upload_4fd1820c46b9d23efdaa0bc2755a9042.png)

# 如何建立一个高质量的 RAG 系统

建立高质量的 RAG 系统对于提高 AI 应用的性能和用户体验至关重要。以下是几个主要原因：

1. 提高回答准确性：高质量的 RAG 系统能够更精准地检索相关信息，为语言模型提供更准确的上下文，从而生成更准确的回答。

2. 增强知识覆盖范围：通过整合外部知识库，RAG 系统可以弥补语言模型在特定领域或最新信息方面的不足，大大扩展了 AI 应用的知识范围。

3. 减少幻觉：优质的 RAG 系统能够提供可靠的信息源，有效降低语言模型产生虚假或不准确信息的可能性。

4. 提升响应速度：高效的检索和处理机制可以缩短系统响应时间，提供更快速的用户体验。

5. 增强可解释性：通过提供信息来源，RAG 系统使 AI 的回答更具可追溯性和可解释性，增加了用户对系统的信任度。

6. 灵活性和可扩展性：高质量的 RAG 系统允许轻松更新和扩展知识库，使 AI 应用能够持续适应新的信息和变化的需求。

因此，构建高质量的 RAG 系统是提升 AI 应用整体性能和用户满意度的关键。接下来，我们将详细探讨如何实现这一目标。

## 1. 选择合适的文档加载器

选择合适的文档加载器是构建高质量 RAG 系统的第一步。文档加载器负责从各种数据源中提取文本内容。以下是一些常见的文档加载器类型(参考[LangChain-文档加载器](https://python.langchain.com/docs/integrations/document_loaders/))：

- 文本文件加载器：用于加载纯文本文件(.txt，.md)
- PDF 加载器：用于加载 PDF 文档
- Word 文档加载器：用于加载 Microsoft Word 文档(.doc, .docx)
- HTML 加载器：用于加载网页内容
- CSV/Excel 加载器：用于加载结构化数据
- 数据库加载器：用于从数据库中提取文本数据

选择加载器时，需要考虑以下因素：

1. 数据源格式：确保选择的加载器能够正确处理你的数据格式。
2. 元数据提取：某些加载器可以提取额外的元数据（如作者、日期等），这对后续处理可能有用。
3. 性能：对于大规模数据，选择高效的加载器很重要。
4. 容错能力：好的加载器应该能够处理常见的文档错误和异常情况。

## 2. 优化文本分割策略

文档分割通常是许多应用程序的关键预处理步骤。它涉及将大型文本分解成更小、更易管理的块。这个过程提供了几个好处，例如确保对不同长度的文档进行一致的处理、克服模型的输入大小限制，以及提高检索系统中使用的文本表示的质量。有几种分割文档的策略，每种策略都有其自身的优势。

### 为什么要对文档进行分割？

- 处理非均匀文档长度：现实世界的文档集合通常包含不同大小的文本。分割确保了对所有文档的一致处理。
- 克服模型限制：许多嵌入模型和语言模型都有最大输入大小限制。分割允许我们处理原本会超出这些限制的文档。
- 提高表示质量：对于较长的文档，嵌入或其他表示的质量可能会下降，因为它们试图捕捉太多信息。分割可以导致每个部分更加集中和准确的表示。
- 增强检索精度：在信息检索系统中，分割可以提高搜索结果的粒度，允许查询与相关文档部分更精确地匹配。
- 优化计算资源：处理较小的文本块可以更加内存高效，并允许更好地并行化处理任务。

### 该怎么分割文档？

#### 基于长度(Length-based):

最直观的策略是根据文档长度进行分割。这种简单而有效的方法确保每个块不超过指定的大小限制。基于长度分割的主要优点：

- 实现简单直接
- 块大小一致
- 易于适应不同的模型要求

基于长度分割的类型：

- 基于标记（Token）：根据标记数量分割文本，这在使用语言模型时很有用。
- 基于字符：根据字符数量分割文本，这可以在不同类型的文本中保持更一致。

#### 基于文本结构(Text-structured):

文本自然地组织成层次结构单元，如段落、句子和单词。我们可以利用这种固有结构来指导我们的分割策略，创建能够保持自然语言流动、维持分割内部语义连贯性，并适应不同级别文本粒度的分割。LangChain 的 RecursiveCharacterTextSplitter 实现了这一概念：

- RecursiveCharacterTextSplitter 尝试保持较大的单元（如段落）完整。
- 如果一个单元超过了块大小，它会移动到下一级（如句子）。
- 如果需要，这个过程会一直持续到单词级别。

#### 基于文档结构(Document-structured):

一些文档具有固有的结构，例如 HTML、Markdown 或 JSON 文件。在这些情况下，根据文档结构进行分割是有益的，因为它通常自然地将语义相关的文本分组。基于结构的分割的主要优势：

- 保留文档的逻辑组织
- 在每个块内保持上下文
- 对于下游任务（如检索或摘要）可能更有效
  基于结构的分割的例子：

基于结构的分割的例子：

- Markdown：基于标题进行分割（例如，#、##、###）
- HTML：使用标签进行分割
- JSON：按对象或数组元素进行分割
- 代码：按函数、类或逻辑块进行分割

#### 基于语义(Semantic meaning-based):

[semantic-chunker（一种基于语义的分割策略）](https://python.langchain.com/docs/how_to/semantic-chunker/)

与之前的方法不同，基于语义的分割实际上考虑了文本的内容。虽然其他方法使用文档或文本结构作为语义含义的代理，但这种方法直接分析文本的语义。有几种方法可以实现这一点，但从概念上讲，当文本含义发生显著变化时，这种方法会分割文本。例如，我们可以使用滑动窗口方法生成嵌入，并比较嵌入以找出显著差异：

- 从前几个句子开始，生成一个嵌入。
- 移动到下一组句子，生成另一个嵌入（例如，使用滑动窗口方法）。
- 比较嵌入以找出显著差异，这表明语义部分之间可能存在"断点"。

这种技术有助于创建语义上更连贯的块，可能会提高检索或摘要等下游任务的质量。

## 3. 嵌入模型

想象一下，能够将任何文本——无论是推文、文档还是书籍的核心内容——提炼成一个简洁的表示形式。这就是嵌入模型的强大之处，它是许多检索系统的核心。嵌入模型将人类语言转换为机器能够理解并快速准确比较的格式。这些模型以文本为输入，生成固定长度的数字数组，即文本语义含义的数字指纹。通过嵌入，搜索系统不仅能根据关键词匹配找到相关文档，还能基于语义理解进行检索。

![](http://192.168.99.63:3000/uploads/upload_eb180635d4e0ecfdcf2dc691a84e8936.png)

嵌入模型领域近年来发生了显著变化。2018 年，谷歌推出了 BERT（双向编码器表示的转换器），这是一个重要的转折点。BERT 将 Transformer 模型应用于文本嵌入，生成简单的向量表示，在各种自然语言处理任务中取得了前所未有的表现。然而，BERT 并未针对高效生成句子嵌入进行优化，这一限制促使了 SBERT（Sentence-BERT）的诞生。SBERT 对 BERT 结构进行了调整，使其能够生成语义丰富的句子嵌入，并通过余弦相似度等相似性度量轻松进行比较，大大降低了在查找相似句子等任务中的计算开销。如今，嵌入模型的生态系统多种多样，众多提供商推出了各自的实现方案。为了在这些选择中找到最优解，研究人员和实践者通常借助于像“大规模文本嵌入基准”（MTEB）这样的基准测试进行客观比较。
