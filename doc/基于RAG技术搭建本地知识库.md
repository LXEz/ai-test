# 什么是 RAG

大型语言模型（LLMs）所实现的最强大应用之一是复杂的问答（Q&A）聊天机器人。这些应用能够回答关于特定源信息的问题。这些应用使用一种被称为检索增强生成（Retrieval Augmented Generation，简称 RAG）的技术。

RAG 是一种用额外数据增强 LLM 知识的技术。

LLM 可以对广泛的主题进行推理，但它们的知识仅限于训练时截止日期之前的公开数据。如果你想构建能够对私有数据或模型截止日期之后引入的数据进行推理的 AI 应用，你需要用它所需的特定信息来增强模型的知识。将适当的信息引入并插入到模型提示中的过程被称为检索增强生成（RAG）。

## 实现 RAG 的一般步骤

一个典型的 RAG 应用通常包含两个主要部分：

- 索引：从数据源摄取数据并建立索引。这通常在离线状态下进行。
- 检索和生成：实际的 RAG 链，它在运行时接收用户查询，从索引中检索相关数据，然后将其传递给模型。

## 建立 Indexing

- Load：首先我们需要加载我们的数据。这通过文档加载器来完成。
- Split：文本分割器将大型文档分割成更小的块。这对于索引数据和将其传递给模型都很有用，因为大块数据更难搜索，而且无法适应模型有限的上下文窗口。
- Embed：嵌入模型将文本转换为向量表示。这些向量用于相似性搜索和检索。
- Store：我们需要一个地方来存储和索引我们的分割，以便之后可以对其进行搜索。这通常使用向量存储和嵌入模型来完成。

![](http://192.168.99.63:3000/uploads/upload_c5d765601537257c91519e4b931a5640.png)

## 检索和生成(Retrieval and generation)

- Retrieve: 给定一个用户输入，使用 Retriever 从存储中检索相关分割。
- Generate: 一个 ChatModel / LLM 使用一个包含问题和检索数据的提示来生成答案。

![](http://192.168.99.63:3000/uploads/upload_4fd1820c46b9d23efdaa0bc2755a9042.png)

# 如何建立一个高质量的 RAG 系统

建立高质量的 RAG 系统对于提高 AI 应用的性能和用户体验至关重要。以下是几个主要原因：

1. 提高回答准确性：高质量的 RAG 系统能够更精准地检索相关信息，为语言模型提供更准确的上下文，从而生成更准确的回答。

2. 增强知识覆盖范围：通过整合外部知识库，RAG 系统可以弥补语言模型在特定领域或最新信息方面的不足，大大扩展了 AI 应用的知识范围。

3. 减少幻觉：优质的 RAG 系统能够提供可靠的信息源，有效降低语言模型产生虚假或不准确信息的可能性。

4. 提升响应速度：高效的检索和处理机制可以缩短系统响应时间，提供更快速的用户体验。

5. 增强可解释性：通过提供信息来源，RAG 系统使 AI 的回答更具可追溯性和可解释性，增加了用户对系统的信任度。

6. 灵活性和可扩展性：高质量的 RAG 系统允许轻松更新和扩展知识库，使 AI 应用能够持续适应新的信息和变化的需求。

因此，构建高质量的 RAG 系统是提升 AI 应用整体性能和用户满意度的关键。接下来，我们将详细探讨如何实现这一目标。

## 1. 选择合适的文档加载器

选择合适的文档加载器是构建高质量 RAG 系统的第一步。文档加载器负责从各种数据源中提取文本内容。以下是一些常见的文档加载器类型(参考[LangChain-文档加载器](https://python.langchain.com/docs/integrations/document_loaders/))：

- 文本文件加载器：用于加载纯文本文件(.txt，.md)
- PDF 加载器：用于加载 PDF 文档
- Word 文档加载器：用于加载 Microsoft Word 文档(.doc, .docx)
- HTML 加载器：用于加载网页内容
- CSV/Excel 加载器：用于加载结构化数据
- 数据库加载器：用于从数据库中提取文本数据

选择加载器时，需要考虑以下因素：

1. 数据源格式：确保选择的加载器能够正确处理你的数据格式。
2. 元数据提取：某些加载器可以提取额外的元数据（如作者、日期等），这对后续处理可能有用。
3. 性能：对于大规模数据，选择高效的加载器很重要。
4. 容错能力：好的加载器应该能够处理常见的文档错误和异常情况。

## 2. 优化文本分割策略

文本分割是 RAG 系统中的关键步骤，它直接影响检索的质量和生成的答案。以下是一些优化文本分割策略的建议：

1. 选择合适的分割方法：

   - 按句子分割：适用于需要保持语义完整性的场景。
   - 按段落分割：适合保留上下文信息的情况。
   - 按固定长度分割：简单但可能会打断语义完整性。
   - 按重叠窗口分割：通过重叠部分保留上下文，但会增加存储需求。

2. 调整分割大小：

   - 太小的分割可能丢失上下文信息。
   - 太大的分割可能包含过多无关信息，影响检索精度。
   - 根据具体应用和模型要求调整，通常在 100-1000 个 token 之间。

3. 保持语义完整性：

   - 避免在句子中间或重要概念处分割。
   - 使用自然语言处理技术识别句子边界和语义单元。

4. 考虑文档结构：

   - 对于结构化文档（如学术论文、技术报告），可以按章节或小节分割。
   - 保留标题、小标题等结构信息，有助于后续检索。

5. 处理特殊内容：

   - 对于表格、图表、代码块等特殊内容，可能需要特殊处理或单独分割。

6. 元数据保留：

   - 在分割过程中保留原始文档的元数据（如文档标题、作者、日期等）。
   - 这些信息可以作为额外特征用于后续的检索和排序。

7. 分割质量检查：
   - 实施自动化检查，确保分割后的文本保持可读性和语义完整性。
   - 可以使用简单的启发式规则或更复杂的机器学习模型来评估分割质量。

通过优化文本分割策略，我们可以显著提高 RAG 系统的检索准确性和生成质量，从而提升整体性能。

## 3. 选择合适的嵌入模型

选择合适的嵌入模型对于构建高效的 RAG 系统至关重要。嵌入模型将文本转换为向量表示，这些向量用于相似性搜索和检索。以下是选择嵌入模型时需要考虑的几个关键因素：

1. 模型性能：

   - 选择在相关任务和数据集上表现良好的模型。
   - 考虑模型在语义相似度、文本分类等任务上的评估结果。

2. 向量维度：

   - 较高维度的向量通常能捕捉更多语义信息，但也会增加存储和计算开销。
   - 根据具体应用需求和资源限制选择合适的维度。

3. 计算效率：

   - 考虑模型的推理速度，特别是在处理大规模数据时。
   - 评估模型在目标硬件上的性能表现。

4. 领域适应性：

   - 选择在目标领域或相似领域上预训练的模型。
   - 考虑是否需要进行领域适应性微调。

5. 多语言支持：

   - 如果系统需要处理多语言内容，选择支持多语言的嵌入模型。

6. 模型大小：

   - 考虑部署环境的资源限制，选择适合的模型大小。
   - 权衡模型大小和性能之间的关系。

7. 更新频率：

   - 考虑模型的更新频率，以确保能够利用最新的改进。

8. 社区支持：

   - 选择有活跃社区支持的模型，便于获取帮助和资源。

9. 许可证：
   - 确保模型的使用许可符合你的项目需求。

一些常用的嵌入模型选择：

- Sentence-BERT (SBERT)：专为语义相似度任务优化的 BERT 变体。
- OpenAI 的 text-embedding-ada-002：性能强大的通用嵌入模型。
- HuggingFace 的 all-MiniLM-L6-v2：轻量级模型，适合资源受限的环境。
- FastText：Facebook 开发的快速文本表示学习模型。
- Universal Sentence Encoder：Google 开发的通用句子编码器。

选择嵌入模型后，还需要考虑如何有效地存储和检索这些向量。常用的向量数据库或相似性搜索引擎包括：

- Faiss：Facebook AI 开发的高效相似性搜索库。
- Annoy：Spotify 开发的近似最近邻搜索库。
- Elasticsearch 与 vector search 插件：结合全文搜索和向量搜索的能力。
- Pinecone：专门为向量搜索优化的云服务。
