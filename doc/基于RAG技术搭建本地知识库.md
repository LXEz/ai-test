# 什么是 RAG

大型语言模型（LLMs）所实现的最强大应用之一是复杂的问答（Q&A）聊天机器人。这些应用能够回答关于特定源信息的问题。这些应用使用一种被称为检索增强生成（Retrieval Augmented Generation，简称 RAG）的技术。

RAG 是一种用额外数据增强 LLM 知识的技术。

LLM 可以对广泛的主题进行推理，但它们的知识仅限于训练时截止日期之前的公开数据。如果你想构建能够对私有数据或模型截止日期之后引入的数据进行推理的 AI 应用，你需要用它所需的特定信息来增强模型的知识。将适当的信息引入并插入到模型提示中的过程被称为检索增强生成（RAG）。

## 实现 RAG 的一般步骤

一个典型的 RAG 应用通常包含两个主要部分：

- 索引：从数据源摄取数据并建立索引。这通常在离线状态下进行。
- 检索和生成：实际的 RAG 链，它在运行时接收用户查询，从索引中检索相关数据，然后将其传递给模型。

## 建立 Indexing

- Load：首先我们需要加载我们的数据。这通过文档加载器来完成。

- Split：文本分割器将大型文档分割成更小的块。这对于索引数据和将其传递给模型都很有用，因为大块数据更难搜索，而且无法适应模型有限的上下文窗口。

- Store：我们需要一个地方来存储和索引我们的分割，以便之后可以对其进行搜索。这通常使用向量存储和嵌入模型来完成。

![](http://192.168.99.63:3000/uploads/upload_c5d765601537257c91519e4b931a5640.png)

## 检索和生成(Retrieval and generation)

- Retrieve: 给定一个用户输入，使用 Retriever 从存储中检索相关分割。
- Generate: 一个 ChatModel / LLM 使用一个包含问题和检索数据的提示来生成答案。

![](http://192.168.99.63:3000/uploads/upload_4fd1820c46b9d23efdaa0bc2755a9042.png)
